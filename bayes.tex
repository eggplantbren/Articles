\documentclass[a4paper, 12pt]{article}
\usepackage{graphicx}
\usepackage[numbers]{natbib}
\usepackage{amsmath}
\usepackage{parskip}
\usepackage{dsfont}
\usepackage[left=3cm,top=3cm,right=3cm]{geometry}

\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\parindent=0cm
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\E}{\mathds{E}}



\title{}
\author{Brendon J. Brewer}

\begin{document}
\sffamily
\maketitle

What is probability? This sounds like a discussion question for a
philosophy class, one of those questions it's fun to think about but which
doesn't have many practical consequences. Surprisingly, this is not the case.
It turns out that different answers to this question lead to completely
different views of how to do statistics and data analysis {\em in practice}.
In the early 20th century this led to a split in the field of statistics,
with intense debates taking place about whose methods and ways of thinking
were better. Unfortunately, the wrong side won the debate and their
ideas still dominate mainstream statistics, a situation which
has exacerbated the reproducibility crises affecting science today.

Here's a common, standard statistical inference problem. An old drug
successfully treats 70\% of patients. To test a new drug, researchers give it
to 100 patients, of whom 76 recover. Based on this evidence, how certain
should we be that the new drug is worse than, identical to, or better than the
old one? If you think it is legitimate to use the mathematics of probability
to study the idea of {\em plausibility}, you are a `Bayesian' (after Reverend
Thomas Bayes, one of the first people to use probability this way). Faced with
this question, your job is to {\em calculate how plausible it is} that the new
drug is much worse, slightly worse, identical to, slightly better, or much better
than the old one, taking into account the result of the experiment. The result
depends on both the experimental result itself, as well as what you assume
about how plausible all of those hypotheses were {\em before you knew the result
of the experiment} --- the dreaded `prior'.


The standard p-value threshold is 0.05. This simply {\em feels} more
convincing than 

Things have improved markedly for Bayesian statisticians over the last few
decades. These days, you're unlikely to encounter any hostility by doing
a Bayesian analysis. By far the dominant attitude these days
is pragmatism. It's possible to do interesting and useful analyses using tools
arising from frequentist thinking, Bayesian thinking, creative invention, or
a mixture of all of these. Most statisticians are happy to do so.
One downside of this ecumenicalism is a reluctance to ask fundamental
questions. Having a strong opinion on this matter has gone out of fashion.
Who's to say one statistical philosophy is better than
another? Aren't all statistical philosophies {\it equally valid} paths to good
data analysis? Frequentism is ``true for me''. As in religion, so in statistics.
If you criticise a colleague for using p-values when posterior probabilities
are clearly more appropriate will lead to accusations of being a `zealot'
\citep{simply_statistics} who should stop `crusading'.
A year ago I went to a talk by prominent `skeptic' Steven Novella, in which
he advocated for a Bayesian approach to judging the plausibility of medical
hypotheses. During the question and answer session, a statistics department colleague of mine raised his hand and said Bayesian statistics was `bullshit' because degrees of plausibility are not empirically measurable. I disagree
strongly, but it was refreshing to see someone willing to argue for a view.

Another, more consequential downside is a reluctance to abandon bad ideas.
Frequentist confidence intervals and p-values should still be taught
--- since so much research is based on them, our students need to know what
they are. In some difficult research problems they might help if a Bayesian solution is too mathematically or computationally difficult to obtain.
Yet it is naive and false to claim that we teach these methods because they're
better or easier than Bayesian ones. I would argue they are both worse and
more difficult. In physics, undergraduate students learn Newton's ideas about
gravity before Einstein's, because they're much easier conceptually and
mathematically, and give the right answer on many problems. The only reason
statisticians think frequentist ideas are easier is that they are used to them.
The only reason they think Bayesian ideas must wait until graduate school is
that the easy textbooks haven't been written (although see
\citep{331, downey}).

\begin{thebibliography}{999} % if there are less than 10 entries, enter a one digit number
\bibitem[Simply Statistics Blog(2013)]{simply_statistics}
http://simplystatistics.org/2013/11/26/statistical-zealots/

\bibitem[]{331}
http://github.com/eggplantbren/STATS331

\bibitem[]{downey}
http://greenteapress.com/thinkbayes/

\end{thebibliography}


\end{document}

